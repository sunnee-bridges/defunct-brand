[build]
  command = "npm run build"
  publish = "dist"

[build.environment]
  NODE_VERSION = "20"

# Stop Netlify from rewriting / → / (prevents surprise 301s)
[build.processing]
  skip_processing = false
[build.processing.html]
  pretty_urls = false

# ---------- Serverless functions ----------
[functions]
  node_bundler = "esbuild"
  directory = "netlify/functions"

# ---------- Redirects ----------

# API routes
[[redirects]]
  from = "/api/brands"
  to = "/.netlify/functions/brands-get"
  status = 200
  force = true

[[redirects]]
  from = "/api/hello"
  to = "/.netlify/functions/hello"
  status = 200
  force = true

# Canonical apex (www -> apex)
[[redirects]]
  from = "https://www.vanishedbrands.com/*"
  to   = "https://vanishedbrands.com/:splat"
  status = 301
  force = true

# --- Brand-specific status handling ---

# 410 for intentionally removed legacy slugs (*.public)
[[redirects]]
  from = "/brand/:name.public"
  to = "/410/"
  status = 410
  force = true

[[redirects]]
  from = "/brand/:name.public/"
  to = "/410/"
  status = 410
  force = true

# Unknown brand paths → serve 404 (no redirect loops; do NOT force)
[[redirects]]
  from = "/brand/*"
  to = "/404.html"
  status = 404

# (Optional) Unknown category paths → 404 as well
[[redirects]]
  from = "/category/*"
  to = "/404.html"
  status = 404

# Download route proxy -> function
[[redirects]]
  from = "/download/:token"
  to = "/.netlify/functions/download-link/:token"
  status = 200
  force = true

# Global catch-all to real 404 page (LAST)
[[redirects]]
  from = "/*"
  to = "/404.html"
  status = 404

# ---------- Headers ----------

# Serve HTML as UTF-8
[[headers]]
  for = "/*.html"
  [headers.values]
    Content-Type = "text/html; charset=utf-8"
    X-Content-Type-Options = "nosniff"
    X-Frame-Options = "DENY"
    Referrer-Policy = "no-referrer-when-downgrade"

# Explicit robots for error documents
[[headers]]
  for = "/404.html"
  [headers.values]
    X-Robots-Tag = "noindex, follow"

[[headers]]
  for = "/410/"
  [headers.values]
    X-Robots-Tag = "noindex, follow"

# JSON as UTF-8
[[headers]]
  for = "/**/*.json"
  [headers.values]
    Content-Type = "application/json; charset=utf-8"
    X-Content-Type-Options = "nosniff"

# Cache hashed static assets (Astro outputs under /_astro)
[[headers]]
  for = "/_astro/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

# (Optional) legacy /assets/*
[[headers]]
  for = "/assets/*"
  [headers.values]
    Cache-Control = "public, max-age=31536000, immutable"

# CSV sample
[[headers]]
  for = "/data/brands-sample.csv"
  [headers.values]
    Content-Type = "text/csv; charset=utf-8"
    Cache-Control = "public, max-age=604800"

# Keep utility/buy pages out of search
[[headers]]
  for = "/buy/"
  [headers.values]
    X-Robots-Tag = "noindex, nofollow"

# Keep download endpoints out of search & caches
[[headers]]
  for = "/download/*"
  [headers.values]
    X-Robots-Tag = "noindex, nofollow"
    Cache-Control = "no-store"

# Sitemaps
[[headers]]
  for = "/sitemap*.xml"
  [headers.values]
    Content-Type = "application/xml; charset=utf-8"
    Cache-Control = "public, max-age=3600"

# ---------- Deploy Preview SEO guard ----------
[context.deploy-preview]
  command = "npm run build"

[[context.deploy-preview.headers]]
  for = "/*"
  [context.deploy-preview.headers.values]
    X-Robots-Tag = "noindex, nofollow"
